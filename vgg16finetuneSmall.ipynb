{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 本文件的目标是：1.测试代码、模型有没有bug 2.看预训练vgg的特征提取是否有效\n",
    "## 具体操作方法：\n",
    "### 模型：在预训练好的vgg16上额外加了一（两）层全连接层，使其输出能分200类\n",
    "### 数据集：原数据集太大了，对于一个仅用于测试评估的模型而言训练起来太慢，我（写了一个代码来完成这件事）抽出原数据集中1000张图片尝试模型能否拟合这个小数据；在这个小数据集上准确率78%上下\n",
    "### 我的设备：2060s显卡（8G显存），32G运行内存"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from torchvision.models import VGG16_Weights\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context # 这行代码为了  下载预训练权重时不出网络问题\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 1008\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "smallBatchPath=\".\"+os.sep+\"smallBatch\"\n",
    "class mySmallBatchDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.labelList=[]\n",
    "        self.imgList=[]\n",
    "        imgList=os.listdir(smallBatchPath)\n",
    "        trans=transforms.ToTensor()\n",
    "        for img in imgList:\n",
    "            op=Image.open(smallBatchPath+os.sep+img).convert('RGB')  # 貌似这是jpg的图所以没有透明通道，所以.convert('RGB')与否不重要\n",
    "            op=op.resize((224,224))\n",
    "            op=trans(op)\n",
    "            labelNum=int(img.split(\"(\")[0])-1\n",
    "            self.labelList.append(labelNum)\n",
    "            self.imgList.append(op)\n",
    "            # print(op.size())  # torch.Size([3, 500, 500])\n",
    "        print(len(self.labelList))\n",
    "        print(len(self.imgList))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.labelList[index],self.imgList[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labelList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "smallBatchDataSet=mySmallBatchDataset()\n",
    "smallBatchDataLoader=DataLoader(smallBatchDataSet,batch_size=100,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class vgg16FineTuneModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1).eval()\n",
    "        # self.finalFC1=nn.Linear(in_features=1000, out_features=1000)\n",
    "        self.finalFC2=nn.Linear(in_features=1000, out_features=200)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            x=self.model(x)\n",
    "        # x=self.finalFC1(x)\n",
    "        # x=F.relu(x)\n",
    "        x=self.finalFC2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "md=vgg16FineTuneModel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def train(model,train_loader,epoch,learning_rate=0.1):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
    "    lossFunction=nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    for i in range(epoch):\n",
    "        wrongNum=0\n",
    "        rightNum=0\n",
    "        print(\"epoch\",i+1,\"/\",epoch)\n",
    "        for batch_idx,(label,data) in enumerate(train_loader):\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output=model.forward(data)\n",
    "\n",
    "            loss=lossFunction(output,label)\n",
    "            loss.backward()\n",
    "\n",
    "            pre=output.argmax(dim=1)\n",
    "            eqq=torch.eq(pre,label)\n",
    "            summ=int(eqq.sum())\n",
    "            rightNum+=summ\n",
    "            wrongNum+=(len(eqq)-summ)\n",
    "\n",
    "            if batch_idx%5==0:\n",
    "                print(\"loss\",loss)\n",
    "                print(\"rightNum\",rightNum,\"wrongNum\",wrongNum)\n",
    "            optimizer.step()\n",
    "        torch.save(model, 'vgg16finetuneSmallTrainSave.pth')\n",
    "        print(\"TOTALrightNum\",rightNum,\"TOTALwrongNum\",wrongNum)\n",
    "        print(\"save\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 5\n",
      "loss tensor(6.4105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 0 wrongNum 100\n",
      "loss tensor(130.9742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 8 wrongNum 592\n",
      "loss tensor(439.5861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 26 wrongNum 1074\n",
      "loss tensor(377.7731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 51 wrongNum 1549\n",
      "TOTALrightNum 76 TOTALwrongNum 1924\n",
      "save\n",
      "epoch 2 / 5\n",
      "loss tensor(489.6523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 16 wrongNum 84\n",
      "loss tensor(514.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 101 wrongNum 499\n",
      "loss tensor(395.2779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 183 wrongNum 917\n",
      "loss tensor(664.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 258 wrongNum 1342\n",
      "TOTALrightNum 319 TOTALwrongNum 1681\n",
      "save\n",
      "epoch 3 / 5\n",
      "loss tensor(471.7179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 32 wrongNum 68\n",
      "loss tensor(384.4083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 128 wrongNum 472\n",
      "loss tensor(434.9992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 235 wrongNum 865\n",
      "loss tensor(449.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 342 wrongNum 1258\n",
      "TOTALrightNum 410 TOTALwrongNum 1590\n",
      "save\n",
      "epoch 4 / 5\n",
      "loss tensor(170.3294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 32 wrongNum 68\n",
      "loss tensor(476.8199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 152 wrongNum 448\n",
      "loss tensor(167.8240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 295 wrongNum 805\n",
      "loss tensor(134.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 436 wrongNum 1164\n",
      "TOTALrightNum 542 TOTALwrongNum 1458\n",
      "save\n",
      "epoch 5 / 5\n",
      "loss tensor(90.8705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 41 wrongNum 59\n",
      "loss tensor(136.1711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 208 wrongNum 392\n",
      "loss tensor(119.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 389 wrongNum 711\n",
      "loss tensor(109.9152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 559 wrongNum 1041\n",
      "TOTALrightNum 682 TOTALwrongNum 1318\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "train(md,smallBatchDataLoader,epoch=5,learning_rate=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10\n",
      "loss tensor(87.6870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 34 wrongNum 66\n",
      "loss tensor(41.9816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 261 wrongNum 339\n",
      "loss tensor(64.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 539 wrongNum 561\n",
      "loss tensor(101.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 803 wrongNum 797\n",
      "TOTALrightNum 1038 TOTALwrongNum 962\n",
      "save\n",
      "epoch 2 / 10\n",
      "loss tensor(35.6325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 55 wrongNum 45\n",
      "loss tensor(74.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 367 wrongNum 233\n",
      "loss tensor(16.5538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 688 wrongNum 412\n",
      "loss tensor(79.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 985 wrongNum 615\n",
      "TOTALrightNum 1236 TOTALwrongNum 764\n",
      "save\n",
      "epoch 3 / 10\n",
      "loss tensor(71.4622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 74 wrongNum 26\n",
      "loss tensor(23.8586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 421 wrongNum 179\n",
      "loss tensor(13.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 761 wrongNum 339\n",
      "loss tensor(18.4966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1097 wrongNum 503\n",
      "TOTALrightNum 1363 TOTALwrongNum 637\n",
      "save\n",
      "epoch 4 / 10\n",
      "loss tensor(84.3818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 73 wrongNum 27\n",
      "loss tensor(51.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 426 wrongNum 174\n",
      "loss tensor(39.1352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 769 wrongNum 331\n",
      "loss tensor(25.2661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1140 wrongNum 460\n",
      "TOTALrightNum 1429 TOTALwrongNum 571\n",
      "save\n",
      "epoch 5 / 10\n",
      "loss tensor(13.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 76 wrongNum 24\n",
      "loss tensor(10.2766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 434 wrongNum 166\n",
      "loss tensor(36.0882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 797 wrongNum 303\n",
      "loss tensor(8.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1151 wrongNum 449\n",
      "TOTALrightNum 1446 TOTALwrongNum 554\n",
      "save\n",
      "epoch 6 / 10\n",
      "loss tensor(12.4857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 73 wrongNum 27\n",
      "loss tensor(17.8359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 460 wrongNum 140\n",
      "loss tensor(12.7226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 835 wrongNum 265\n",
      "loss tensor(7.3983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1206 wrongNum 394\n",
      "TOTALrightNum 1511 TOTALwrongNum 489\n",
      "save\n",
      "epoch 7 / 10\n",
      "loss tensor(5.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 79 wrongNum 21\n",
      "loss tensor(13.9141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 483 wrongNum 117\n",
      "loss tensor(7.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 885 wrongNum 215\n",
      "loss tensor(9.8206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1287 wrongNum 313\n",
      "TOTALrightNum 1584 TOTALwrongNum 416\n",
      "save\n",
      "epoch 8 / 10\n",
      "loss tensor(6.2996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 79 wrongNum 21\n",
      "loss tensor(6.4499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 485 wrongNum 115\n",
      "loss tensor(6.7450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 872 wrongNum 228\n",
      "loss tensor(11.4222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1272 wrongNum 328\n",
      "TOTALrightNum 1594 TOTALwrongNum 406\n",
      "save\n",
      "epoch 9 / 10\n",
      "loss tensor(6.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 81 wrongNum 19\n",
      "loss tensor(8.8191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 479 wrongNum 121\n",
      "loss tensor(11.3808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 881 wrongNum 219\n",
      "loss tensor(3.3559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1287 wrongNum 313\n",
      "TOTALrightNum 1614 TOTALwrongNum 386\n",
      "save\n",
      "epoch 10 / 10\n",
      "loss tensor(3.7409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 91 wrongNum 9\n",
      "loss tensor(10.9671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 512 wrongNum 88\n",
      "loss tensor(6.4844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 941 wrongNum 159\n",
      "loss tensor(15.9150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1342 wrongNum 258\n",
      "TOTALrightNum 1668 TOTALwrongNum 332\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "train(md,smallBatchDataLoader,epoch=10,learning_rate=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10\n",
      "loss tensor(3.9938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 88 wrongNum 12\n",
      "loss tensor(2.9943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 520 wrongNum 80\n",
      "loss tensor(4.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 963 wrongNum 137\n",
      "loss tensor(2.7919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1418 wrongNum 182\n",
      "TOTALrightNum 1775 TOTALwrongNum 225\n",
      "save\n",
      "epoch 2 / 10\n",
      "loss tensor(5.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 94 wrongNum 6\n",
      "loss tensor(1.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 543 wrongNum 57\n",
      "loss tensor(1.7684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 998 wrongNum 102\n",
      "loss tensor(1.4070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1472 wrongNum 128\n",
      "TOTALrightNum 1838 TOTALwrongNum 162\n",
      "save\n",
      "epoch 3 / 10\n",
      "loss tensor(1.4778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 91 wrongNum 9\n",
      "loss tensor(2.1655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 564 wrongNum 36\n",
      "loss tensor(2.7424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1022 wrongNum 78\n",
      "loss tensor(5.7036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1499 wrongNum 101\n",
      "TOTALrightNum 1871 TOTALwrongNum 129\n",
      "save\n",
      "epoch 4 / 10\n",
      "loss tensor(4.1744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 96 wrongNum 4\n",
      "loss tensor(1.7380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 569 wrongNum 31\n",
      "loss tensor(0.5202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1050 wrongNum 50\n",
      "loss tensor(6.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1513 wrongNum 87\n",
      "TOTALrightNum 1898 TOTALwrongNum 102\n",
      "save\n",
      "epoch 5 / 10\n",
      "loss tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(0.8287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 573 wrongNum 27\n",
      "loss tensor(1.7828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1048 wrongNum 52\n",
      "loss tensor(0.5089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1533 wrongNum 67\n",
      "TOTALrightNum 1920 TOTALwrongNum 80\n",
      "save\n",
      "epoch 6 / 10\n",
      "loss tensor(0.3021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 97 wrongNum 3\n",
      "loss tensor(3.6416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 582 wrongNum 18\n",
      "loss tensor(0.6739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1061 wrongNum 39\n",
      "loss tensor(2.7032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1545 wrongNum 55\n",
      "TOTALrightNum 1929 TOTALwrongNum 71\n",
      "save\n",
      "epoch 7 / 10\n",
      "loss tensor(0.7535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 94 wrongNum 6\n",
      "loss tensor(0.8362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 578 wrongNum 22\n",
      "loss tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1054 wrongNum 46\n",
      "loss tensor(0.7236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1539 wrongNum 61\n",
      "TOTALrightNum 1918 TOTALwrongNum 82\n",
      "save\n",
      "epoch 8 / 10\n",
      "loss tensor(0.6859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 96 wrongNum 4\n",
      "loss tensor(0.4835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 580 wrongNum 20\n",
      "loss tensor(4.2114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1065 wrongNum 35\n",
      "loss tensor(0.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1546 wrongNum 54\n",
      "TOTALrightNum 1929 TOTALwrongNum 71\n",
      "save\n",
      "epoch 9 / 10\n",
      "loss tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(0.3055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 584 wrongNum 16\n",
      "loss tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1072 wrongNum 28\n",
      "loss tensor(0.1003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1559 wrongNum 41\n",
      "TOTALrightNum 1941 TOTALwrongNum 59\n",
      "save\n",
      "epoch 10 / 10\n",
      "loss tensor(0.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 98 wrongNum 2\n",
      "loss tensor(1.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 584 wrongNum 16\n",
      "loss tensor(6.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1066 wrongNum 34\n",
      "loss tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1554 wrongNum 46\n",
      "TOTALrightNum 1947 TOTALwrongNum 53\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "train(md,smallBatchDataLoader,epoch=10,learning_rate=0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10\n",
      "loss tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(0.5041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 590 wrongNum 10\n",
      "loss tensor(0.3679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1076 wrongNum 24\n",
      "loss tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1569 wrongNum 31\n",
      "TOTALrightNum 1964 TOTALwrongNum 36\n",
      "save\n",
      "epoch 2 / 10\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 596 wrongNum 4\n",
      "loss tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1094 wrongNum 6\n",
      "loss tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1591 wrongNum 9\n",
      "TOTALrightNum 1987 TOTALwrongNum 13\n",
      "save\n",
      "epoch 3 / 10\n",
      "loss tensor(8.4485e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 598 wrongNum 2\n",
      "loss tensor(0.2322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1094 wrongNum 6\n",
      "loss tensor(0.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1591 wrongNum 9\n",
      "TOTALrightNum 1990 TOTALwrongNum 10\n",
      "save\n",
      "epoch 4 / 10\n",
      "loss tensor(0.4672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 596 wrongNum 4\n",
      "loss tensor(7.6458e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1096 wrongNum 4\n",
      "loss tensor(3.3482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1593 wrongNum 7\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 5 / 10\n",
      "loss tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 596 wrongNum 4\n",
      "loss tensor(0.2034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1095 wrongNum 5\n",
      "loss tensor(1.7904e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1593 wrongNum 7\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 6 / 10\n",
      "loss tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 98 wrongNum 2\n",
      "loss tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 595 wrongNum 5\n",
      "loss tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1092 wrongNum 8\n",
      "loss tensor(3.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1590 wrongNum 10\n",
      "TOTALrightNum 1988 TOTALwrongNum 12\n",
      "save\n",
      "epoch 7 / 10\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(5.4952e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 600 wrongNum 0\n",
      "loss tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1099 wrongNum 1\n",
      "loss tensor(1.7051e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1598 wrongNum 2\n",
      "TOTALrightNum 1993 TOTALwrongNum 7\n",
      "save\n",
      "epoch 8 / 10\n",
      "loss tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.1807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 597 wrongNum 3\n",
      "loss tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1095 wrongNum 5\n",
      "loss tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1592 wrongNum 8\n",
      "TOTALrightNum 1990 TOTALwrongNum 10\n",
      "save\n",
      "epoch 9 / 10\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 599 wrongNum 1\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1096 wrongNum 4\n",
      "loss tensor(2.9776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1592 wrongNum 8\n",
      "TOTALrightNum 1992 TOTALwrongNum 8\n",
      "save\n",
      "epoch 10 / 10\n",
      "loss tensor(6.1134e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(8.0432e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 595 wrongNum 5\n",
      "loss tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1094 wrongNum 6\n",
      "loss tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1591 wrongNum 9\n",
      "TOTALrightNum 1989 TOTALwrongNum 11\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "train(md,smallBatchDataLoader,epoch=10,learning_rate=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10\n",
      "loss tensor(4.9719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 98 wrongNum 2\n",
      "loss tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 595 wrongNum 5\n",
      "loss tensor(8.3565e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1094 wrongNum 6\n",
      "loss tensor(2.8242e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1591 wrongNum 9\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 2 / 10\n",
      "loss tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(4.6249e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 598 wrongNum 2\n",
      "loss tensor(3.7838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1095 wrongNum 5\n",
      "loss tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1593 wrongNum 7\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 3 / 10\n",
      "loss tensor(2.9443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(1.3185e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 598 wrongNum 2\n",
      "loss tensor(4.7752e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1097 wrongNum 3\n",
      "loss tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1593 wrongNum 7\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 4 / 10\n",
      "loss tensor(6.7388e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 597 wrongNum 3\n",
      "loss tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1097 wrongNum 3\n",
      "loss tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1594 wrongNum 6\n",
      "TOTALrightNum 1992 TOTALwrongNum 8\n",
      "save\n",
      "epoch 5 / 10\n",
      "loss tensor(1.1418e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.9922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 598 wrongNum 2\n",
      "loss tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1097 wrongNum 3\n",
      "loss tensor(4.1245e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1595 wrongNum 5\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 6 / 10\n",
      "loss tensor(9.0229e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.8213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 598 wrongNum 2\n",
      "loss tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1096 wrongNum 4\n",
      "loss tensor(7.1382e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1593 wrongNum 7\n",
      "TOTALrightNum 1991 TOTALwrongNum 9\n",
      "save\n",
      "epoch 7 / 10\n",
      "loss tensor(4.7668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(6.4209e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 596 wrongNum 4\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1095 wrongNum 5\n",
      "loss tensor(2.9581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1592 wrongNum 8\n",
      "TOTALrightNum 1989 TOTALwrongNum 11\n",
      "save\n",
      "epoch 8 / 10\n",
      "loss tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(2.3337e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 597 wrongNum 3\n",
      "loss tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1096 wrongNum 4\n",
      "loss tensor(3.7449e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1595 wrongNum 5\n",
      "TOTALrightNum 1993 TOTALwrongNum 7\n",
      "save\n",
      "epoch 9 / 10\n",
      "loss tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 99 wrongNum 1\n",
      "loss tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 597 wrongNum 3\n",
      "loss tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1096 wrongNum 4\n",
      "loss tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1594 wrongNum 6\n",
      "TOTALrightNum 1992 TOTALwrongNum 8\n",
      "save\n",
      "epoch 10 / 10\n",
      "loss tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 100 wrongNum 0\n",
      "loss tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 600 wrongNum 0\n",
      "loss tensor(4.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1095 wrongNum 5\n",
      "loss tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rightNum 1595 wrongNum 5\n",
      "TOTALrightNum 1993 TOTALwrongNum 7\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "train(md,smallBatchDataLoader,epoch=10,learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "torch.save(md, 'vgg16finetuneSmall.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 结论：代码可以拟合小训练集，没有致命问题，可以考虑在整个训练集上运行"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}